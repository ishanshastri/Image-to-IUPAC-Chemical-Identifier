{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import deepchem as dc\n",
    "import transformers\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/homebrew/lib/python3.11/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/homebrew/lib/python3.11/site-packages (from opencv-python) (1.26.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# %pip install cv2\n",
    "# !pip show cv2\n",
    "DATA_PATH = 'CompiledDataset/relevant_data.csv'\n",
    "SMILES_PATH = 'CompiledDataset/data.csv'\n",
    "\n",
    "import sys\n",
    "from scipy import spatial\n",
    "!{sys.executable} -m pip install opencv-python\n",
    "import cv2\n",
    "import pandas as pd\n",
    "# from Model import GetData, DATA_PATH\n",
    "\n",
    "#Retrieve dataframe from stored csv file\n",
    "def GetData(file):\n",
    "    \"\"\"\n",
    "    Retrieve data from file, return pandas dataframe\n",
    "    \"\"\"\n",
    "    d = pd.read_csv(file)\n",
    "    Data = d['Images']\n",
    "    Data = pd.concat([Data, d[[str(i) for i in range(128)]]], axis=\"columns\")\n",
    "    Data['SMILES'] = pd.read_csv(SMILES_PATH)['SMILES']\n",
    "    return Data\n",
    "\n",
    "def _getEmbedding(index, df):\n",
    "    \"\"\"\n",
    "    Return an embedding from dataframe (consisting of only the embeddings)\n",
    "    \"\"\"\n",
    "    return df.iloc[index].to_numpy()\n",
    "\n",
    "def _get_closest_embedding(vector, embeds):\n",
    "    #euclidean = lambda x, y: \n",
    "    #distances = {embed:spatial.distance.cosine(vector, embed) for embed in embeds}\n",
    "    #sorted_dists = sorted(distances.items(), key=lambda x:x[1])\n",
    "    distances = [(embed, spatial.distance.cosine(vector, embed)) for embed in embeds]\n",
    "    sorted_dists = sorted(distances, key=lambda x:x[1])\n",
    "    return sorted_dists[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = GetData(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Images</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>SMILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ImageData/uh0.png</td>\n",
       "      <td>0.008918</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>-0.004025</td>\n",
       "      <td>-0.007159</td>\n",
       "      <td>-0.004339</td>\n",
       "      <td>-0.002224</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>-0.006694</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005933</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>C[NH+](CC1=C(C=CC=C1Cl)F)CN2C(=O)CC3(C2=O)CCCCC3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ImageData/uh1.png</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.007546</td>\n",
       "      <td>-0.005600</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.004105</td>\n",
       "      <td>-0.003233</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>-0.009206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>-0.005300</td>\n",
       "      <td>-0.003507</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>CC1=C(C=C(C=C1)C(=O)NC2=C(C=C(C=C2)I)C3=NC4=CC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ImageData/uh2.png</td>\n",
       "      <td>0.010540</td>\n",
       "      <td>-0.001101</td>\n",
       "      <td>-0.010949</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>-0.007081</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>-0.004051</td>\n",
       "      <td>-0.007896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>-0.007659</td>\n",
       "      <td>-0.009448</td>\n",
       "      <td>-0.005587</td>\n",
       "      <td>-0.004743</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>-0.004380</td>\n",
       "      <td>-0.006842</td>\n",
       "      <td>0.008730</td>\n",
       "      <td>COC1=CC=C(C=C1)CCN2C(=O)CC(SC2=NC3=CC=C(C=C3)O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ImageData/uh3.png</td>\n",
       "      <td>0.009642</td>\n",
       "      <td>-0.005712</td>\n",
       "      <td>-0.007004</td>\n",
       "      <td>-0.001866</td>\n",
       "      <td>-0.005760</td>\n",
       "      <td>-0.001075</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>-0.006042</td>\n",
       "      <td>-0.010296</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005524</td>\n",
       "      <td>-0.001443</td>\n",
       "      <td>-0.003787</td>\n",
       "      <td>-0.007360</td>\n",
       "      <td>-0.007552</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>-0.001459</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>CCOC1=C(C=CC(=C1)/C=C(\\C#N)/C2=CC=C(C=C2)[N+](...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ImageData/uh4.png</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>-0.005728</td>\n",
       "      <td>-0.009615</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>-0.000722</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>-0.005061</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003132</td>\n",
       "      <td>-0.005669</td>\n",
       "      <td>-0.006349</td>\n",
       "      <td>-0.004257</td>\n",
       "      <td>0.006115</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>-0.000608</td>\n",
       "      <td>-0.003798</td>\n",
       "      <td>-0.004487</td>\n",
       "      <td>CC1=C(C(=O)N(N1C)C2=CC=CC=C2)CN(CCN3CCCC3)C(=O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>ImageData/uh1245.png</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.007894</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.004995</td>\n",
       "      <td>-0.004694</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010144</td>\n",
       "      <td>-0.001874</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.007178</td>\n",
       "      <td>-0.009206</td>\n",
       "      <td>0.008637</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>-0.005269</td>\n",
       "      <td>-0.002090</td>\n",
       "      <td>C1=CC=C(C(=C1)NC(=O)C2=C(C(=CC(=C2)Cl)[N+](=O)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>ImageData/uh1246.png</td>\n",
       "      <td>-0.001969</td>\n",
       "      <td>-0.006363</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>-0.002361</td>\n",
       "      <td>-0.002082</td>\n",
       "      <td>-0.001974</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005810</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>-0.008886</td>\n",
       "      <td>-0.002668</td>\n",
       "      <td>-0.007688</td>\n",
       "      <td>-0.002359</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>CC1=CC2=C(C=C1O)C(=C(N2CC3=CC(=CC=C3)Cl)C)C(=O)N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>ImageData/uh1247.png</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>-0.005750</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>-0.005731</td>\n",
       "      <td>-0.003018</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.004922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>0.007616</td>\n",
       "      <td>0.008276</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>C[C@H]1C(=O)NC2=C(O1)C=CC(=C2)C(=O)[C@@H](C)Cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>ImageData/uh1248.png</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>-0.004366</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>0.008283</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>-0.004097</td>\n",
       "      <td>-0.004064</td>\n",
       "      <td>-0.006380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>-0.002594</td>\n",
       "      <td>-0.007957</td>\n",
       "      <td>-0.001054</td>\n",
       "      <td>-0.010196</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.010379</td>\n",
       "      <td>0.006236</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>C1C2=C(C=C(C=C2)NC(=O)NC3=CC=CC=C3Br)NS1(=O)=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>ImageData/uh1249.png</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>-0.003508</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.006031</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>-0.005369</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007366</td>\n",
       "      <td>-0.001765</td>\n",
       "      <td>-0.004335</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>-0.007559</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>-0.000773</td>\n",
       "      <td>0.007561</td>\n",
       "      <td>-0.008088</td>\n",
       "      <td>C1=CC=C(C=C1)CCN(C2=CC=C(C=C2)NC(=S)NC(=O)C3=C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Images         0         1         2         3         4  \\\n",
       "0        ImageData/uh0.png  0.008918  0.007185  0.003843 -0.004025 -0.007159   \n",
       "1        ImageData/uh1.png  0.005314  0.007546 -0.005600  0.001770  0.004105   \n",
       "2        ImageData/uh2.png  0.010540 -0.001101 -0.010949  0.010823  0.006059   \n",
       "3        ImageData/uh3.png  0.009642 -0.005712 -0.007004 -0.001866 -0.005760   \n",
       "4        ImageData/uh4.png  0.008436 -0.005728 -0.009615  0.002174  0.001339   \n",
       "...                    ...       ...       ...       ...       ...       ...   \n",
       "1245  ImageData/uh1245.png  0.005178  0.000309  0.000833  0.002428  0.007894   \n",
       "1246  ImageData/uh1246.png -0.001969 -0.006363 -0.001005  0.004978  0.002395   \n",
       "1247  ImageData/uh1247.png  0.003921 -0.005750 -0.001652  0.009373 -0.005731   \n",
       "1248  ImageData/uh1248.png  0.000305 -0.004366  0.002527  0.004344  0.008283   \n",
       "1249  ImageData/uh1249.png  0.010026 -0.003508  0.001906  0.006031  0.001980   \n",
       "\n",
       "             5         6         7         8  ...       119       120  \\\n",
       "0    -0.004339 -0.002224  0.004571 -0.006694  ... -0.005933  0.002324   \n",
       "1    -0.003233  0.001038  0.001464 -0.009206  ...  0.001146  0.002944   \n",
       "2    -0.007081  0.004326 -0.004051 -0.007896  ...  0.001325 -0.007659   \n",
       "3    -0.001075  0.004211 -0.006042 -0.010296  ... -0.005524 -0.001443   \n",
       "4    -0.000722  0.004063 -0.005061  0.002492  ... -0.003132 -0.005669   \n",
       "...        ...       ...       ...       ...  ...       ...       ...   \n",
       "1245  0.000818  0.000616  0.004995 -0.004694  ... -0.010144 -0.001874   \n",
       "1246 -0.002361 -0.002082 -0.001974  0.000024  ... -0.005810  0.005080   \n",
       "1247 -0.003018  0.004601  0.007990  0.004922  ...  0.003553  0.000097   \n",
       "1248  0.002675 -0.004097 -0.004064 -0.006380  ...  0.003972 -0.002594   \n",
       "1249  0.002095  0.001736  0.004575 -0.005369  ... -0.007366 -0.001765   \n",
       "\n",
       "           121       122       123       124       125       126       127  \\\n",
       "0    -0.000274  0.001278  0.006330 -0.000406  0.005050  0.003521  0.005719   \n",
       "1     0.003084  0.001922  0.002732 -0.005300 -0.003507  0.004510  0.000134   \n",
       "2    -0.009448 -0.005587 -0.004743  0.007540 -0.004380 -0.006842  0.008730   \n",
       "3    -0.003787 -0.007360 -0.007552  0.001964  0.002989 -0.001459  0.000290   \n",
       "4    -0.006349 -0.004257  0.006115  0.006779 -0.000608 -0.003798 -0.004487   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1245  0.002277  0.007178 -0.009206  0.008637  0.000162 -0.005269 -0.002090   \n",
       "1246 -0.008886 -0.002668 -0.007688 -0.002359  0.005512  0.003034  0.001387   \n",
       "1247  0.001365  0.000523  0.002336  0.004126  0.007616  0.008276  0.002631   \n",
       "1248 -0.007957 -0.001054 -0.010196  0.006981  0.010379  0.006236  0.005025   \n",
       "1249 -0.004335  0.004771 -0.007559 -0.000307 -0.000773  0.007561 -0.008088   \n",
       "\n",
       "                                                 SMILES  \n",
       "0      C[NH+](CC1=C(C=CC=C1Cl)F)CN2C(=O)CC3(C2=O)CCCCC3  \n",
       "1     CC1=C(C=C(C=C1)C(=O)NC2=C(C=C(C=C2)I)C3=NC4=CC...  \n",
       "2     COC1=CC=C(C=C1)CCN2C(=O)CC(SC2=NC3=CC=C(C=C3)O...  \n",
       "3     CCOC1=C(C=CC(=C1)/C=C(\\C#N)/C2=CC=C(C=C2)[N+](...  \n",
       "4     CC1=C(C(=O)N(N1C)C2=CC=CC=C2)CN(CCN3CCCC3)C(=O...  \n",
       "...                                                 ...  \n",
       "1245  C1=CC=C(C(=C1)NC(=O)C2=C(C(=CC(=C2)Cl)[N+](=O)...  \n",
       "1246   CC1=CC2=C(C=C1O)C(=C(N2CC3=CC(=CC=C3)Cl)C)C(=O)N  \n",
       "1247     C[C@H]1C(=O)NC2=C(O1)C=CC(=C2)C(=O)[C@@H](C)Cl  \n",
       "1248     C1C2=C(C=C(C=C2)NC(=O)NC3=CC=CC=C3Br)NS1(=O)=O  \n",
       "1249  C1=CC=C(C=C1)CCN(C2=CC=C(C=C2)NC(=S)NC(=O)C3=C...  \n",
       "\n",
       "[1250 rows x 130 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# cifar = tf.keras.datasets.cifar100\n",
    "# (x_train, y_train), (x_test, y_test) = cifar.load_data()\n",
    "# model = tf.keras.applications.ResNet50(\n",
    "#     include_top=True,\n",
    "#     weights=None,\n",
    "#     input_shape=(32, 32, 3),\n",
    "#     classes=100,)\n",
    "\n",
    "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "# model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"accuracy\"])\n",
    "# model.fit(x_train, y_train, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training and test data\n",
    "# keras.preprocessing.image.load_img()\n",
    "TrainX = np.asarray([keras.utils.img_to_array(keras.preprocessing.image.load_img(path=data['Images'][i], color_mode='grayscale').resize((150, 150))) for i in range(0, 1000)], dtype=np.float16)\n",
    "TrainY = np.array([_getEmbedding(i, data.drop(['Images', 'SMILES'], axis=1)) for i in range(0, 1000)])#, dtype=np.float16)\n",
    "\n",
    "TestX = np.asarray([keras.utils.img_to_array(keras.preprocessing.image.load_img(path=data['Images'][i], color_mode='grayscale').resize((150, 150))) for i in range(1000, 1249)], dtype=np.float16)\n",
    "TestY = np.asarray([_getEmbedding(i, data.drop(['Images', 'SMILES'], axis=1)) for i in range(1000, 1249)])#, dtype=np.float16)\n",
    "\n",
    "AllEmbeddings = np.concatenate((TrainY, TestY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 150, 150, 1), (1000, 128))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainX.shape, TrainY.shape#, TrainY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.9177275e-03,  7.1854717e-03,  3.8428665e-03, -4.0253940e-03,\n",
       "       -7.1591362e-03, -4.3388084e-03, -2.2244342e-03,  4.5708410e-03,\n",
       "       -6.6944393e-03, -7.9990910e-03, -4.2905040e-03,  1.1734873e-02,\n",
       "       -6.5311664e-03,  1.9662790e-03,  6.8848200e-03,  6.0130400e-03,\n",
       "        6.6165370e-04,  5.5164765e-03, -6.4791483e-03,  4.8608356e-03,\n",
       "       -1.8425450e-04, -5.2225525e-03, -1.9734392e-03, -7.1963600e-03,\n",
       "       -7.5456296e-04, -8.2247204e-04,  9.5439370e-03, -5.3567146e-03,\n",
       "       -8.1392920e-03, -3.4479846e-04, -7.4726716e-03, -6.9147090e-03,\n",
       "       -1.3519467e-03, -4.7649564e-03, -6.3540163e-03,  9.1820860e-04,\n",
       "       -1.7171575e-03,  3.8439300e-03,  5.0288877e-03, -7.0183566e-03,\n",
       "       -6.3349665e-03, -9.6803333e-04, -3.5540640e-03,  3.4882694e-03,\n",
       "        7.1226470e-03,  4.0810510e-03, -5.2643553e-03, -7.9339750e-04,\n",
       "        4.9102370e-04, -7.8875620e-03,  1.0330998e-02,  7.8057590e-03,\n",
       "        3.1532740e-03,  1.5166359e-03,  5.3257262e-03,  7.5360010e-03,\n",
       "        5.8633517e-03, -5.9254235e-03, -3.3369833e-03,  5.7787570e-03,\n",
       "       -8.4386110e-04,  3.8847523e-03,  5.4430743e-03,  6.0115317e-03,\n",
       "        4.7575138e-03,  5.1887166e-03, -4.5548338e-03,  4.6744780e-03,\n",
       "        9.4504650e-03,  1.3748673e-03, -7.7998643e-03, -9.0320995e-03,\n",
       "        4.6269740e-03,  4.5750730e-03, -3.3534148e-03, -3.5230610e-03,\n",
       "       -8.0108430e-03, -4.1291523e-03, -5.1914030e-03, -1.9381437e-03,\n",
       "       -7.3285694e-03, -4.6054116e-03, -7.7764774e-03, -1.4921344e-03,\n",
       "       -2.9051418e-03,  6.2191384e-03,  4.3839244e-03, -2.7929794e-03,\n",
       "        3.3127116e-03, -8.2098227e-04,  5.1052630e-03, -4.2747990e-03,\n",
       "       -7.9927060e-04,  8.6730930e-03,  2.7351762e-04,  8.1065610e-03,\n",
       "       -2.0804750e-03, -2.8388617e-05,  5.1883800e-03, -5.4402887e-03,\n",
       "       -2.9828810e-03, -5.6249190e-03,  3.3389130e-03,  6.0746917e-03,\n",
       "        8.6048890e-03,  4.3747853e-03,  8.2909920e-03, -7.5326255e-03,\n",
       "       -4.4090710e-03, -4.5944136e-03, -2.2823534e-03, -4.1432000e-03,\n",
       "       -1.2280596e-03, -1.9455723e-03,  3.0324468e-03,  4.5757270e-03,\n",
       "       -6.3072937e-03,  7.8513810e-03,  4.9562235e-03, -5.9329187e-03,\n",
       "        2.3243325e-03, -2.7403267e-04,  1.2776133e-03,  6.3300150e-03,\n",
       "       -4.0604372e-04,  5.0501430e-03,  3.5214014e-03,  5.7186780e-03])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">147968</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">18,940,032</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m147968\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m18,940,032\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,032,704</span> (72.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,032,704\u001b[0m (72.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,032,704</span> (72.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,032,704\u001b[0m (72.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 282ms/step - accuracy: 0.0080 - loss: 18680.6328 - val_accuracy: 0.0000e+00 - val_loss: 4.1633e-05\n",
      "Epoch 2/3\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 271ms/step - accuracy: 0.0000e+00 - loss: 4.1331e-05 - val_accuracy: 0.0000e+00 - val_loss: 4.1348e-05\n",
      "Epoch 3/3\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 278ms/step - accuracy: 6.5932e-04 - loss: 4.0958e-05 - val_accuracy: 0.0201 - val_loss: 4.0305e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "# model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "# model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(128))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "'''training model USING GENERATOR \n",
    "history = model.fit(generator(Data['Images'], Data.drop(['Images'], axis=1), 32),\n",
    " validation_data = (TestX, TestY), steps_per_epoch = 1000 // 32,\n",
    " epochs = 10)\n",
    "\n",
    "\n",
    "#Train model\n",
    "history = model.fit(TrainX, TrainY,\n",
    " validation_data = (TestX, TestY), \n",
    " epochs = 10)\n",
    "'''\n",
    "history = model.fit(TrainX, TrainY,\n",
    " validation_data = (TestX, TestY), \n",
    " epochs = 3)\n",
    "\n",
    "# Running samples\n",
    "#sample_chemical_embed = AllEmbeddings[50]\n",
    "sample_chemical_diagram = TrainX[50]\n",
    "#model_prediction = model.predict([sample_chemical_diagram])\n",
    "model_prediction = model(np.reshape(sample_chemical_diagram, (1, 150, 150)))\n",
    "closest_embed = _get_closest_embedding(vector=model_prediction[0], embeds=AllEmbeddings)[0]\n",
    "\n",
    "# TODO retrieve corresponding iupac, compare w/ actual iupac\n",
    " \n",
    "#def loadAndTrainLSTM()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: keras\n",
      "Version: 3.3.2\n",
      "Summary: Multi-backend Keras.\n",
      "Home-page: https://github.com/keras-team/keras\n",
      "Author: Keras team\n",
      "Author-email: keras-users@googlegroups.com\n",
      "License: Apache License 2.0\n",
      "Location: /opt/homebrew/lib/python3.11/site-packages\n",
      "Requires: absl-py, h5py, ml-dtypes, namex, numpy, optree, rich\n",
      "Required-by: tensorflow-macos\n"
     ]
    }
   ],
   "source": [
    "history.history['accuracy']\n",
    "!pip show keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Vectorization\"\"\"\n",
    "\n",
    "# vectorize_layer = TextVectorization(\n",
    "#         max_tokens=vocab_size,\n",
    "#         output_mode=\"int\",\n",
    "#         standardize=custom_standardization,\n",
    "#         output_sequence_length=max_seq,\n",
    "#     )\n",
    "#     vectorize_layer.adapt(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functional model\"\"\"\n",
    "# from keras.layers import MultiHeadAttention, Dense, BatchNormalization, Input, \n",
    "# timestep_dimension = self.num_exercises*self.num_exercise_features\n",
    "\n",
    "# # Timestep layers\n",
    "# input_timesteps = Input(shape=(self.num_steps, timestep_dimension))\n",
    "# lstm_1 = LSTM(units=125, activation=\"tanh\", return_sequences=False)(input_timesteps)\n",
    "# batch_norm_1 = BatchNormalization()(lstm_1)\n",
    "# dense_1 = Dense(units=timestep_dimension/2)(batch_norm_1)\n",
    "\n",
    "# embeds = np.array(self.embeddings)\n",
    "# downsampled_embeds = np.array(Dense(units=timestep_dimension/2)(embeds))\n",
    "# def concate_in_embeddings(downsampled_timesteps):\n",
    "#     batch_size = K.shape(downsampled_timesteps)[0]\n",
    "#     tiled_embeddings = K.tile(np.array([downsampled_embeds]), (batch_size, 1, 1))\n",
    "#     return tiled_embeddings\n",
    "    \n",
    "# embeddings_processed = Lambda(concate_in_embeddings)(dense_1)\n",
    "# downsampled_embeddings = embeddings_processed # Consider adding more layers in between\n",
    "\n",
    "\n",
    "# mat_multed_timesteps = embeddings_multiplier([downsampled_embeddings, dense_1])\n",
    "# batch_norm_2 = BatchNormalization()(mat_multed_timesteps)\n",
    "# post_mat_layer_1 = Dense(units=timestep_dimension*2)(batch_norm_2)\n",
    "\n",
    "# # Probability layer\n",
    "# prob_layer = tfp.layers.DistributionLambda(\n",
    "#     lambda t: tfd.Normal(loc=t[..., :timestep_dimension], \n",
    "#                         scale=0.01*tf.math.softplus(t[..., timestep_dimension:])))(post_mat_layer_1)#(tf.Variable(post_mat_layer_1))\n",
    "# output = prob_layer # maybe add more layers\n",
    "\n",
    "# model = Model(inputs=input_timesteps, outputs=output)\n",
    "# #model.compile(optimizer=\"RMSprop\", loss=\"mse\", metrics=None)\n",
    "# model.compile(optimizer=\"RMSprop\", loss=neg_log_lik)\n",
    "\n",
    "# self.model = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Images         0         1         2         3         4  \\\n",
      "0        ImageData/uh0.png  0.008918  0.007185  0.003843 -0.004025 -0.007159   \n",
      "1        ImageData/uh1.png  0.005314  0.007546 -0.005600  0.001770  0.004105   \n",
      "2        ImageData/uh2.png  0.010540 -0.001101 -0.010949  0.010823  0.006059   \n",
      "3        ImageData/uh3.png  0.009642 -0.005712 -0.007004 -0.001866 -0.005760   \n",
      "4        ImageData/uh4.png  0.008436 -0.005728 -0.009615  0.002174  0.001339   \n",
      "...                    ...       ...       ...       ...       ...       ...   \n",
      "1245  ImageData/uh1245.png  0.005178  0.000309  0.000833  0.002428  0.007894   \n",
      "1246  ImageData/uh1246.png -0.001969 -0.006363 -0.001005  0.004978  0.002395   \n",
      "1247  ImageData/uh1247.png  0.003921 -0.005750 -0.001652  0.009373 -0.005731   \n",
      "1248  ImageData/uh1248.png  0.000305 -0.004366  0.002527  0.004344  0.008283   \n",
      "1249  ImageData/uh1249.png  0.010026 -0.003508  0.001906  0.006031  0.001980   \n",
      "\n",
      "             5         6         7         8  ...       118       119  \\\n",
      "0    -0.004339 -0.002224  0.004571 -0.006694  ...  0.004956 -0.005933   \n",
      "1    -0.003233  0.001038  0.001464 -0.009206  ... -0.000326  0.001146   \n",
      "2    -0.007081  0.004326 -0.004051 -0.007896  ...  0.004891  0.001325   \n",
      "3    -0.001075  0.004211 -0.006042 -0.010296  ...  0.005720 -0.005524   \n",
      "4    -0.000722  0.004063 -0.005061  0.002492  ...  0.007897 -0.003132   \n",
      "...        ...       ...       ...       ...  ...       ...       ...   \n",
      "1245  0.000818  0.000616  0.004995 -0.004694  ...  0.002253 -0.010144   \n",
      "1246 -0.002361 -0.002082 -0.001974  0.000024  ... -0.000454 -0.005810   \n",
      "1247 -0.003018  0.004601  0.007990  0.004922  ... -0.002789  0.003553   \n",
      "1248  0.002675 -0.004097 -0.004064 -0.006380  ... -0.001486  0.003972   \n",
      "1249  0.002095  0.001736  0.004575 -0.005369  ...  0.004379 -0.007366   \n",
      "\n",
      "           120       121       122       123       124       125       126  \\\n",
      "0     0.002324 -0.000274  0.001278  0.006330 -0.000406  0.005050  0.003521   \n",
      "1     0.002944  0.003084  0.001922  0.002732 -0.005300 -0.003507  0.004510   \n",
      "2    -0.007659 -0.009448 -0.005587 -0.004743  0.007540 -0.004380 -0.006842   \n",
      "3    -0.001443 -0.003787 -0.007360 -0.007552  0.001964  0.002989 -0.001459   \n",
      "4    -0.005669 -0.006349 -0.004257  0.006115  0.006779 -0.000608 -0.003798   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1245 -0.001874  0.002277  0.007178 -0.009206  0.008637  0.000162 -0.005269   \n",
      "1246  0.005080 -0.008886 -0.002668 -0.007688 -0.002359  0.005512  0.003034   \n",
      "1247  0.000097  0.001365  0.000523  0.002336  0.004126  0.007616  0.008276   \n",
      "1248 -0.002594 -0.007957 -0.001054 -0.010196  0.006981  0.010379  0.006236   \n",
      "1249 -0.001765 -0.004335  0.004771 -0.007559 -0.000307 -0.000773  0.007561   \n",
      "\n",
      "           127  \n",
      "0     0.005719  \n",
      "1     0.000134  \n",
      "2     0.008730  \n",
      "3     0.000290  \n",
      "4    -0.004487  \n",
      "...        ...  \n",
      "1245 -0.002090  \n",
      "1246  0.001387  \n",
      "1247  0.002631  \n",
      "1248  0.005025  \n",
      "1249 -0.008088  \n",
      "\n",
      "[1250 rows x 129 columns]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.preprocessing.text.Tokenizer()\n",
    "# print(data)\n",
    "smiles = data['SMILES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --pre deepchem\n",
    "# import deepchem\n",
    "# deepchem.molnet.TransformerGenerator.create_transformer\n",
    "# import deepchem as dc\n",
    "# # deepchem.trans.Transformer.\n",
    "# import transformers\n",
    "smiles_tokenizer = dc.feat.SmilesTokenizer('vocab.txt')#deepchem/feat/tests/data/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 22, 22, 22, 22, 13]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_tokenizer('====')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([150, 150, 1]), TensorShape([128]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tf.data.Dataset.from_tensor_slices((TrainX, TrainY)))[0][0].shape, \\\n",
    "list(tf.data.Dataset.from_tensor_slices((TrainX, TrainY)))[0][1].shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_ds=tf.data.Dataset.from_tensor_slices((TrainX, TrainY)).padded_batch(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 527ms/step - accuracy: 0.0171 - loss: 4.0014e-05 - val_accuracy: 0.0201 - val_loss: 3.9936e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 509ms/step - accuracy: 0.0171 - loss: 3.9964e-05 - val_accuracy: 0.0201 - val_loss: 3.9885e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 502ms/step - accuracy: 0.0171 - loss: 3.9914e-05 - val_accuracy: 0.0201 - val_loss: 3.9834e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 503ms/step - accuracy: 0.0171 - loss: 3.9863e-05 - val_accuracy: 0.0201 - val_loss: 3.9782e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 512ms/step - accuracy: 0.0171 - loss: 3.9811e-05 - val_accuracy: 0.0201 - val_loss: 3.9730e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 516ms/step - accuracy: 0.0171 - loss: 3.9759e-05 - val_accuracy: 0.0201 - val_loss: 3.9677e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 514ms/step - accuracy: 0.0171 - loss: 3.9706e-05 - val_accuracy: 0.0201 - val_loss: 3.9624e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 536ms/step - accuracy: 0.0171 - loss: 3.9653e-05 - val_accuracy: 0.0201 - val_loss: 3.9570e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 546ms/step - accuracy: 0.0171 - loss: 3.9599e-05 - val_accuracy: 0.0201 - val_loss: 3.9515e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 584ms/step - accuracy: 0.0171 - loss: 3.9544e-05 - val_accuracy: 0.0201 - val_loss: 3.9460e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 556ms/step - accuracy: 0.0171 - loss: 3.9489e-05 - val_accuracy: 0.0201 - val_loss: 3.9405e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 588ms/step - accuracy: 0.0171 - loss: 3.9434e-05 - val_accuracy: 0.0201 - val_loss: 3.9349e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 527ms/step - accuracy: 0.0171 - loss: 3.9378e-05 - val_accuracy: 0.0201 - val_loss: 3.9292e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 615ms/step - accuracy: 0.0171 - loss: 3.9321e-05 - val_accuracy: 0.0201 - val_loss: 3.9235e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 596ms/step - accuracy: 0.0171 - loss: 3.9264e-05 - val_accuracy: 0.0201 - val_loss: 3.9178e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 559ms/step - accuracy: 0.0171 - loss: 3.9207e-05 - val_accuracy: 0.0201 - val_loss: 3.9119e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 556ms/step - accuracy: 0.0171 - loss: 3.9149e-05 - val_accuracy: 0.0201 - val_loss: 3.9061e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 527ms/step - accuracy: 0.0171 - loss: 3.9090e-05 - val_accuracy: 0.0201 - val_loss: 3.9002e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 548ms/step - accuracy: 0.0171 - loss: 3.9031e-05 - val_accuracy: 0.0201 - val_loss: 3.8942e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 591ms/step - accuracy: 0.0171 - loss: 3.8971e-05 - val_accuracy: 0.0201 - val_loss: 3.8882e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(emb_ds, validation_data = (TestX, TestY), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smiles_tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 591), dtype=float32, numpy=\n",
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_layer = tf.keras.layers.Lambda(lambda x: tf.one_hot(x, smiles_tokenizer.vocab_size))\n",
    "# one_hot_layer(np.array([[34, 66]], dtype=np.int32))\n",
    "\n",
    "tf.one_hot(np.array([0, 34, 66]), smiles_tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Reshape, concatenate, Input, Lambda, Flatten, Activation, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "class TfProbabilityModel:\n",
    "    pass\n",
    "class ProbabilityEmbeddingsModel(TfProbabilityModel):\n",
    "    def __init__(self, num_exercises=700, n_steps=10, n_features_per_ex=2, n_lstm_units=125, dropout_enabled=True, hyper_params=None, pre_trained_model=None, dir=None, metadata=None, embeds=None):\n",
    "        self.embeddings_model = sentence_embedding()\n",
    "\n",
    "        #if not (isinstance(embeds, np.ndarray) and not isinstance(embeds, list)) or embeds == None or len(embeds) == 0:\n",
    "        #    print(\"WARNING: No Embeddings Found; Model will not compile. Recompile model with embeddings sent\")\n",
    "        #    return\n",
    "\n",
    "        if metadata != None:\n",
    "            # Load from metadata\n",
    "            self.model_metadata = metadata\n",
    "            self.num_exercises = metadata['num_exercises']\n",
    "            self.num_steps = metadata['num_steps']\n",
    "            self.num_exercise_features = metadata['num_exercise_features']\n",
    "            self.dropout_enabled = metadata['dropout_enabled']\n",
    "            self.num_lstm_units = metadata['num_lstm_units']\n",
    "            self.hyper_parameters = metadata['hyper_parameters']\n",
    "            self.custom_objects = None\n",
    "            self.embeddings = metadata['embeddings']\n",
    "            if dir != None:\n",
    "                self.model = load_model(dir)\n",
    "                return\n",
    "                \n",
    "        if embeds is None:\n",
    "            print(\"WARNING: No Embeddings Found; Model will not compile. Recompile model with embeddings sent\")\n",
    "            return\n",
    "        # Initialize/get embeddings\n",
    "        self.embeddings = embeds\n",
    "\n",
    "        super().__init__(num_exercises, n_steps, n_features_per_ex, n_lstm_units, dropout_enabled, hyper_params, pre_trained_model)\n",
    "        self.set_model_metadata(model_type='ProbabilityEmbeddingsModel')\n",
    "\n",
    "    def set_model_metadata(self, model_type):\n",
    "        self.model_metadata['embeddings'] = self.embeddings.tolist()\n",
    "        super().set_model_metadata(model_type)\n",
    "\n",
    "    def _compile(self):\n",
    "        #if self.embeddings == None or len(self.embeddings) == 0:\n",
    "        #    print(\"WARNING: No Embeddings Found; Model will not compile. Recompile model with embeddings sent\")\n",
    "        #    return\n",
    "\n",
    "        timestep_dimension = self.num_exercises*self.num_exercise_features\n",
    "\n",
    "        # Timestep layers\n",
    "        input_timesteps = Input(shape=(self.num_steps, timestep_dimension))\n",
    "        lstm_1 = LSTM(units=125, activation=\"tanh\", return_sequences=False)(input_timesteps)\n",
    "        batch_norm_1 = BatchNormalization()(lstm_1)\n",
    "        dense_1 = Dense(units=timestep_dimension/2)(batch_norm_1)\n",
    "\n",
    "        embeds = np.array(self.embeddings)\n",
    "        downsampled_embeds = np.array(Dense(units=timestep_dimension/2)(embeds))\n",
    "        def concate_in_embeddings(downsampled_timesteps):\n",
    "            batch_size = K.shape(downsampled_timesteps)[0]\n",
    "            tiled_embeddings = K.tile(np.array([downsampled_embeds]), (batch_size, 1, 1))\n",
    "            return tiled_embeddings\n",
    "            \n",
    "        embeddings_processed = Lambda(concate_in_embeddings)(dense_1)\n",
    "        downsampled_embeddings = embeddings_processed # Consider adding more layers in between\n",
    "\n",
    "        class EmbeddingsMatMultLayer(keras.layers.Layer):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                \n",
    "            def call(self, inputs):\n",
    "                x, y = inputs\n",
    "                return K.batch_dot(x, y)\n",
    "            \n",
    "        embeddings_multiplier = EmbeddingsMatMultLayer()\n",
    "        mat_multed_timesteps = embeddings_multiplier([downsampled_embeddings, dense_1])\n",
    "        batch_norm_2 = BatchNormalization()(mat_multed_timesteps)\n",
    "        post_mat_layer_1 = Dense(units=timestep_dimension*2)(batch_norm_2)\n",
    "\n",
    "        # Probability layer\n",
    "        prob_layer = tfp.layers.DistributionLambda(\n",
    "            lambda t: tfd.Normal(loc=t[..., :timestep_dimension], \n",
    "                                scale=0.01*tf.math.softplus(t[..., timestep_dimension:])))(post_mat_layer_1)#(tf.Variable(post_mat_layer_1))\n",
    "        output = prob_layer # maybe add more layers\n",
    "\n",
    "        model = Model(inputs=input_timesteps, outputs=output)\n",
    "        #model.compile(optimizer=\"RMSprop\", loss=\"mse\", metrics=None)\n",
    "        model.compile(optimizer=\"RMSprop\", loss=neg_log_lik)\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "    def train(self, x, y, epochs=50, batch_size=32, use_cache=True): # TODO\n",
    "        return super().train(x, y, epochs, batch_size, use_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('encoder.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
